# ğŸ”§ Checkpoint Conversion Fix - Quick Start Guide

## é—®é¢˜ç—‡çŠ¶

- âœ… æ‚¨çš„æƒ…å†µï¼šOLMO2 èµ·å§‹ loss = 4~5
- âŒ æœŸæœ›å€¼ï¼šèµ·å§‹ loss = ~2.xï¼ˆå®˜æ–¹æ•°å€¼ï¼‰

## å¿«é€Ÿè¯Šæ–­ (3 åˆ†é’Ÿ)

### æ­¥éª¤ 1: æ£€æŸ¥ç°æœ‰ checkpoint

```bash
python diagnose_checkpoint.py \
    --checkpoint /path/to/your/converted/checkpoint \
    --model allenai/OLMo-2-1124-7B \
    --trust_remote_code
```

**æŸ¥çœ‹è¾“å‡ºä¸­çš„å…³é”®ä¿¡æ¯ï¼š**
```
Parameter counts:
  HuggingFace: X,XXX,XXX parameters
  DCP:         Y,YYY,YYY parameters  # â† å¦‚æœ Y != Xï¼Œè¯´æ˜æœ‰å‚æ•°ä¸¢å¤±
  Difference:  Z,ZZZ parameters (Z.ZZ%)

âŒ CRITICAL: Parameter count mismatch! This will cause loss issues.
```

å¦‚æœçœ‹åˆ° `Parameter count mismatch`ï¼Œè¯´æ˜è½¬æ¢æœ‰é—®é¢˜ âœ…

---

## å¿«é€Ÿä¿®å¤ (5 åˆ†é’Ÿ)

### æ–¹æ¡ˆ A: ä½¿ç”¨æ”¹è¿›çš„è½¬æ¢è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
# é‡æ–°è½¬æ¢ checkpoint
python convert_hf_to_dcp_fixed.py \
    --model allenai/OLMo-2-1124-7B \
    --checkpoint /path/to/new/checkpoint \
    --trust_remote_code

# å¦‚æœéœ€è¦æ·»åŠ  future_predictor
python convert_hf_to_dcp_fixed.py \
    --model allenai/OLMo-2-1124-7B \
    --checkpoint /path/to/new/checkpoint \
    --trust_remote_code \
    --include_future_predictor \
    --future_predictor_head_type linear
```

**è¾“å‡ºåº”è¯¥æ˜¾ç¤ºï¼š**
```
âœ… Parameter counts match!
  Model parameters:       7,609,876,480
  Model buffers:          0
  State dict tensors:     7,609,876,480
```

### æ–¹æ¡ˆ B: ä¿®æ”¹ç°æœ‰çš„ convert_hf_to_dcp.py

åœ¨ `flame/utils/convert_hf_to_dcp.py` ç¬¬ 40 è¡Œï¼Œæ›¿æ¢ï¼š

```python
# åŸå§‹ä»£ç ï¼ˆå¯èƒ½æœ‰é—®é¢˜ï¼‰
state_dict = model.state_dict()
```

æ”¹ä¸ºï¼š

```python
# ä¿®å¤åçš„ä»£ç 
from torch.distributed.checkpoint.state_dict import get_model_state_dict
state_dict = get_model_state_dict(model)
```

ç„¶åé‡æ–°è¿è¡Œè½¬æ¢ã€‚

---

## éªŒè¯ä¿®å¤ (2 åˆ†é’Ÿ)

### 1. å†æ¬¡è¯Šæ–­æ–°çš„ checkpoint

```bash
python diagnose_checkpoint.py \
    --checkpoint /path/to/new/checkpoint \
    --model allenai/OLMo-2-1124-7B \
    --trust_remote_code
```

**æœŸæœ›è¾“å‡ºï¼š**
```
âœ… Parameter counts match
âœ… No shape mismatches found
```

### 2. å¿«é€Ÿ loss æµ‹è¯•

```python
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

# åŠ è½½åŸå§‹æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained(
    "allenai/OLMo-2-1124-7B",
    trust_remote_code=True
)
tokenizer = AutoTokenizer.from_pretrained("allenai/OLMo-2-1124-7B")

# æµ‹è¯•æ•°æ®
text = "The capital of France is"
inputs = tokenizer(text, return_tensors="pt")

# è®¡ç®— loss
with torch.no_grad():
    outputs = model(**inputs, labels=inputs["input_ids"])
    print(f"Loss: {outputs.loss.item():.4f}")
```

**æœŸæœ›ç»“æœï¼š** loss åº”è¯¥åœ¨ 2-3 å·¦å³ï¼ˆå–å†³äºå…·ä½“æ–‡æœ¬ï¼‰

---

## å®Œæ•´å·¥ä½œæµç¨‹

```bash
# 1. è¯Šæ–­æ—§ checkpoint
python diagnose_checkpoint.py \
    --checkpoint /path/to/old/checkpoint \
    --model allenai/OLMo-2-1124-7B \
    --trust_remote_code

# 2. ä½¿ç”¨ä¿®å¤çš„è„šæœ¬é‡æ–°è½¬æ¢
python convert_hf_to_dcp_fixed.py \
    --model allenai/OLMo-2-1124-7B \
    --checkpoint /path/to/new/checkpoint \
    --trust_remote_code

# 3. éªŒè¯æ–° checkpoint
python diagnose_checkpoint.py \
    --checkpoint /path/to/new/checkpoint \
    --model allenai/OLMo-2-1124-7B \
    --trust_remote_code

# 4. é‡æ–°å¼€å§‹è®­ç»ƒ
# ä½¿ç”¨æ–°çš„ checkpoint è·¯å¾„æ›´æ–°ä½ çš„è®­ç»ƒé…ç½®
```

---

## å¦‚æœé—®é¢˜ä»ç„¶å­˜åœ¨

å¦‚æœä¿®å¤å loss ä»ç„¶æ˜¯ 4~5ï¼Œæ£€æŸ¥ä»¥ä¸‹æ–¹é¢ï¼š

### 1. Tokenizer é—®é¢˜

```python
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("allenai/OLMo-2-1124-7B", trust_remote_code=True)
print(f"Vocab size: {tokenizer.vocab_size}")
print(f"Pad token ID: {tokenizer.pad_token_id}")
print(f"EOS token ID: {tokenizer.eos_token_id}")

# ç¡®ä¿è®­ç»ƒè„šæœ¬ä¸­ä½¿ç”¨äº†ç›¸åŒçš„ tokenizer
```

### 2. æ¨¡å‹é…ç½®é—®é¢˜

```python
from transformers import AutoConfig

config = AutoConfig.from_pretrained("allenai/OLMo-2-1124-7B")
print(f"Model vocab_size: {config.vocab_size}")
print(f"Hidden size: {config.hidden_size}")
print(f"Num layers: {config.num_hidden_layers}")

# ç¡®ä¿è¿™äº›é…ç½®ä¸è®­ç»ƒæ—¶ä½¿ç”¨çš„ä¸€è‡´
```

### 3. æ•°æ®é¢„å¤„ç†é—®é¢˜

æ£€æŸ¥ä½ çš„æ•°æ®å¤„ç†ä»£ç ï¼š
- `attention_mask` æ˜¯å¦æ­£ç¡®
- `labels` ä¸­çš„ padding æ˜¯å¦è®¾ç½®ä¸º `-100`
- åºåˆ—é•¿åº¦æ˜¯å¦åˆç†

### 4. Loss è®¡ç®—é—®é¢˜

æ£€æŸ¥ `flame/train.py` ä¸­çš„ loss è®¡ç®—ï¼š
- æ˜¯å¦ä½¿ç”¨äº†æ­£ç¡®çš„ `ignore_index=-100`
- æ˜¯å¦åº”ç”¨äº†æ­£ç¡®çš„ reductionï¼ˆmean/sumï¼‰

---

## å¸¸è§é—®é¢˜

### Q: ä¸ºä»€ä¹ˆ `model.state_dict()` å¯èƒ½ä¸å®Œæ•´ï¼Ÿ

A: `model.state_dict()` å¯èƒ½é—æ¼ï¼š
- æŸäº› buffersï¼ˆå¦‚ RoPE çš„é¢‘ç‡ç¼“å­˜ï¼‰
- ç‰¹æ®Šçš„æŒä¹…åŒ–çŠ¶æ€
- è½¬æ¢åçš„æƒé‡æ ¼å¼

`get_model_state_dict` æ˜¯ PyTorch åˆ†å¸ƒå¼è®­ç»ƒæ¨èçš„æ–¹æ³•ï¼Œä¼šæ­£ç¡®å¤„ç†è¿™äº›æƒ…å†µã€‚

### Q: è¯Šæ–­è„šæœ¬æŠ¥é”™æ€ä¹ˆåŠï¼Ÿ

A: å¸¸è§é”™è¯¯ï¼š
```bash
# å¦‚æœæŠ¥ "No module named 'torch.distributed.checkpoint'"
pip install torch>=2.0.0

# å¦‚æœæŠ¥ transformers ç›¸å…³é”™è¯¯
pip install transformers>=4.30.0 --upgrade
```

### Q: è½¬æ¢åçš„ checkpoint å¯ä»¥ç›´æ¥ç”¨äºè®­ç»ƒå—ï¼Ÿ

A: æ˜¯çš„ï¼ŒTorchTitan çš„ `CheckpointManager` ä¼šè‡ªåŠ¨åŒ…è£…å®ƒã€‚ä½†è¦ç¡®ä¿ï¼š
- checkpoint è·¯å¾„æ­£ç¡®
- åœ¨ `JobConfig` ä¸­è®¾ç½® `initial_load_path` æŒ‡å‘ä½ çš„ checkpoint
- è®¾ç½® `initial_load_model_weights_only=True`ï¼ˆç¬¬ä¸€æ¬¡åŠ è½½ï¼‰

---

## æ–‡ä»¶æ¸…å•

åˆ›å»ºçš„æ–‡ä»¶ï¼š
1. âœ… `diagnose_checkpoint.py` - è¯Šæ–­å·¥å…·
2. âœ… `convert_hf_to_dcp_fixed.py` - ä¿®å¤çš„è½¬æ¢è„šæœ¬
3. âœ… `CHECKPOINT_CONVERSION_ISSUE.md` - è¯¦ç»†åˆ†æ
4. âœ… `CHECKPOINT_FIX_GUIDE.md` - æœ¬æŒ‡å—

åŸå§‹æ–‡ä»¶ï¼š
- `flame/utils/convert_hf_to_dcp.py` - åŸå§‹è½¬æ¢è„šæœ¬ï¼ˆå¯èƒ½æœ‰é—®é¢˜ï¼‰
- `flame/utils/convert_dcp_to_hf.py` - åå‘è½¬æ¢

---

## é¢„æœŸç»“æœ

ä¿®å¤åï¼š
- âœ… å‚æ•°æ•°é‡åŒ¹é…ï¼š0 å·®å¼‚
- âœ… èµ·å§‹ lossï¼š~2.xï¼ˆä¸å®˜æ–¹ä¸€è‡´ï¼‰
- âœ… è®­ç»ƒæ­£å¸¸æ”¶æ•›

å¦‚æœä»æœ‰é—®é¢˜ï¼Œè¯·æä¾›ï¼š
1. `diagnose_checkpoint.py` çš„å®Œæ•´è¾“å‡º
2. è®­ç»ƒæ—¶çš„å®Œæ•´ config
3. è®­ç»ƒæ—¥å¿—çš„å‰å‡ ä¸ª steps

---

## ç«‹å³å¼€å§‹

**æœ€å¿«çš„éªŒè¯æ–¹æ³•**ï¼ˆ1 æ¡å‘½ä»¤ï¼‰ï¼š

```bash
# è¯Šæ–­ + å¯¹æ¯”
python diagnose_checkpoint.py \
    --checkpoint /path/to/your/checkpoint \
    --model allenai/OLMo-2-1124-7B \
    --trust_remote_code | tee diagnosis.log

# æŸ¥çœ‹ diagnosis.log ä¸­çš„ "Parameter count mismatch" å’Œ "Missing in DCP"
```

å¦‚æœå‘ç°é—®é¢˜ï¼Œè¿è¡Œï¼š

```bash
# é‡æ–°è½¬æ¢
python convert_hf_to_dcp_fixed.py \
    --model allenai/OLMo-2-1124-7B \
    --checkpoint /path/to/new/checkpoint \
    --trust_remote_code

# å†æ¬¡éªŒè¯
python diagnose_checkpoint.py \
    --checkpoint /path/to/new/checkpoint \
    --model allenai/OLMo-2-1124-7B \
    --trust_remote_code
```

å®Œæˆï¼ğŸ‰
